---
title: "Project 2"
author: "Group 6, Xavier Genelin, Dave Bergeron"
date: "10/19/2021"
output: github_document
---

I don't think we need all of these libraries. We can keep them for now but the project doesn't require anything with SQL so those can be removed later.

Dave:  Agree, one of my bad habits not pruning the list from one assignment to the other.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(rmarkdown)
library(haven)
library(readxl)
library(parallel)
library(purrr)
library(lattice)
library(caret)
library(ciTools)
library(plot3D)
library(MuMIn)
library(devtools)
library(pls)
library(corrplot)
library(car)
library(class)
library(gbm)
library(randomForest)
```

# Introduction

We'll load in the (Online News Popularity Data Set)[https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity]  from the UCI Machine Learning Repository. From this data, we'll break it down into 6 different groups based on the data channel: lifestyle, entertainment, bus, socmed, tech, and world. 

# Load Data and Make Groups

```{r}
news <- read_csv("OnlineNewsPopularity.csv")

# Remove the url column from the dataset
news <- news %>% select(!url)

# Subset data and remove the data_channel_is columns
## lifestyle
lifestyle <- news %>% filter(data_channel_is_lifestyle == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

# entertainment
entertainment <- news %>% filter(data_channel_is_entertainment == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

# bus
bus <- news %>% filter(data_channel_is_bus == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

# socmed
socmed <- news %>% filter(data_channel_is_socmed == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

# tech
tech <- news %>% filter(data_channel_is_tech == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

# world
world <- news %>% filter(data_channel_is_world == 1) %>% select(!c(data_channel_is_bus, data_channel_is_entertainment, data_channel_is_lifestyle, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))

```

# Summarizations
```{r}
# trying this with the world data set first.
set.seed(55)
trainIndex <- createDataPartition(world$shares, p = 0.7, list = FALSE)

# bus
busTrain <- bus[trainIndex, ]
busTest <- bus[-trainIndex, ]

# entertainment
entertainTrain <- entertainment[trainIndex, ]
entertainTest <- entertainment[-trainIndex, ]

# lifestyle 
lifestyleTrain <- lifestyle[trainIndex, ]
lifestyleTest <- lifestyle[-trainIndex, ]

# news 
newsTrain <- news[trainIndex, ]
newsTest <- news[-trainIndex, ]

# socmed 
socmedTrain <- socmed[trainIndex, ]
socmedTest <- socmed[-trainIndex, ]

# tech 
techTrain <- tech[trainIndex, ]
techTest <- tech[-trainIndex, ]

# world
worldTrain <- world[trainIndex, ]
worldTest <- world[-trainIndex, ]
```

I was hoping to see the correlation plot for the variables to see what was most related to shares. Kind of rough with the large number of variables

```{r}
corrs <- cor(worldTrain)

corrplot(corrs, tl.cex = 0.5)
```


# EDA items

## Graphs

### Graph 1

```{r}
# still working on this...need to play around with the data a bit more.
p <- ggplot(worldTrain, aes(x=shares)) + 
  geom_boxplot() + coord_flip()
p
```


### Graph 2

### Graph 3

## Contingency Tables

### 2-way Contingency Table

Shows token count in titles on Mondays 

```{r, eval=TRUE, echo=TRUE}
table(worldTrain$n_tokens_title, worldTrain$weekday_is_monday)
```

### 3-Way Contingency Table

xxx

```{r, eval=TRUE, echo=TRUE}

```



# Modeling

In this section we're going to compare the following models: random forest, linear regression, and two ensemble models (we can fill this in when we decide which two to do). Each of the models will be trying to predict the amount of shares for each of the data channels. 



## Random Forest

Tried to use all the variables, took forever to run. Initially had 10 cv and 1:15 trees. Made the cv to 5 and tried smaller mtry values but it still takes a long time. 

```{r}
set.seed(55)
# takes forever to run
# rfFit <- train(shares ~ ., data = worldTrain, method = "rf", trControl = trainControl(method = "cv", number = 5), tuneGrid = expand.grid(mtry = 1:8))
```

## Linear Regression
```{r}
#Model 1 -  Selecting predictors based on relevancy from ANOVA results after running the summary from model using all predictors in another model - 4 predictors
worldtrainglmfit <- lm(shares ~ num_imgs + kw_min_avg + kw_max_avg + kw_avg_avg, data = worldTrain, trControl = trainControl(method = "cv", number = 10), preProcess = c("center", "scale"))

pred1 <- predict(worldtrainglmfit, newdata = worldTest)

postResample(pred1, obs = worldTest$shares)
```

```{r}
# Xavier model
olsFit <- train(shares ~ num_imgs + kw_min_avg + kw_max_avg + kw_avg_avg, data = worldTrain, trControl = trainControl(method = "cv", number = 5))

olsPred <- predict(olsFit, worldTest)

postResample(olsPred, obs = worldTest$shares)[2]
```

## Ensemble 

### Boosted Tree

This is the boosted tree model using all predictors in the `worldTrain` data set.

```{r}
set.seed(30)
wtFit <- train(shares ~ ., data = worldTrain,
               method = "gbm",
               preProcess = c("center", "scale"),
               trControl = trainControl(method = "cv",
                                        number = 5),
               tuneGrid = expand.grid(.n.trees = seq(25, 200, by = 25), .interaction.depth = seq(1, 4, by = 1), .shrinkage = (0.1), .n.minobsinnode = (10)))
wtFit
```

#### Boosted Tree Test Results

xxxx

```{r, eval = FALSE}

```
# Comparison


## Test for project 2

Test

```{r, echo=TRUE, eval=FALSE}

```


